{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uTRwwFGrrxcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e41fab-d90c-467e-92f4-6ecc29c0f15e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution after SMOTE: Counter({0: 539, 1: 539, 2: 539})\n",
            "Optimizing ExtraTreesClassifier...\n",
            "Model: ExtraTreesClassifier\n",
            "Train Mean Accuracy: 0.6074, Train Std Dev: 0.0661\n",
            "Test Accuracy: 0.5357, Precision: 0.5532, Recall: 0.5357, F1 Score: 0.5385\n",
            "\n",
            "Optimizing MLPClassifier...\n",
            "Model: MLPClassifier\n",
            "Train Mean Accuracy: 0.6092, Train Std Dev: 0.0691\n",
            "Test Accuracy: 0.5000, Precision: 0.4988, Recall: 0.5000, F1 Score: 0.4993\n",
            "\n",
            "Final Model Evaluation Results:\n",
            "                  Model  Train Mean Accuracy  Train Std Dev  Test Accuracy  \\\n",
            "0  ExtraTreesClassifier             0.607373       0.066061       0.535714   \n",
            "1         MLPClassifier             0.609229       0.069114       0.500000   \n",
            "\n",
            "   Precision    Recall  F1 Score  \n",
            "0   0.553219  0.535714  0.538510  \n",
            "1   0.498784  0.500000  0.499301  \n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for clean output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"/content/training_with_glove embeddings_split.xlsx\"  # Replace with your dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "X = data.drop([\"input\", \"Class\"], axis=1)  # Drop 'input' and target\n",
        "y = data[\"Class\"]\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE to balance the training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check the class distribution after SMOTE\n",
        "balanced_class_distribution = Counter(y_train_smote)\n",
        "print(\"Class distribution after SMOTE:\", balanced_class_distribution)\n",
        "\n",
        "# Define 2 models\n",
        "models = {\n",
        "    \"ExtraTreesClassifier\": ExtraTreesClassifier(),\n",
        "    \"MLPClassifier\": MLPClassifier(),\n",
        "}\n",
        "\n",
        "# Define hyperparameter grids for each model\n",
        "extended_param_grids = {\n",
        "    \"ExtraTreesClassifier\": {\n",
        "        \"n_estimators\": [100, 200, 500],\n",
        "        \"max_depth\": [None, 10, 20],\n",
        "        \"max_features\": [\"sqrt\", \"log2\"],\n",
        "        \"min_samples_split\": [2, 5, 10],\n",
        "    },\n",
        "    \"MLPClassifier\": {\n",
        "        \"hidden_layer_sizes\": [(50,), (100,), (50, 50)],\n",
        "        \"activation\": [\"relu\", \"tanh\", \"logistic\"],\n",
        "        \"solver\": [\"adam\", \"sgd\"],\n",
        "        \"learning_rate_init\": [0.001, 0.01, 0.1],\n",
        "        \"max_iter\": [200, 500, 1000],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Train, optimize, and evaluate each model\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Optimizing {model_name}...\")\n",
        "\n",
        "    # Use extended hyperparameters if available\n",
        "    if extended_param_grids.get(model_name):\n",
        "        random_search = RandomizedSearchCV(\n",
        "            model,\n",
        "            param_distributions=extended_param_grids[model_name],\n",
        "            n_iter=20,  # Number of parameter settings to sample\n",
        "            cv=5,\n",
        "            scoring=\"accuracy\",\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "        )\n",
        "        random_search.fit(X_train_smote, y_train_smote)\n",
        "        best_model = random_search.best_estimator_\n",
        "    else:\n",
        "        best_model = model\n",
        "        best_model.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(best_model, X_train_smote, y_train_smote, cv=5, scoring=\"accuracy\")\n",
        "    train_mean_accuracy = np.mean(cv_scores)\n",
        "    train_std_dev = np.std(cv_scores)\n",
        "\n",
        "    # Test set evaluation\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
        "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
        "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Train Mean Accuracy: {train_mean_accuracy:.4f}, Train Std Dev: {train_std_dev:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\\n\")\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Train Mean Accuracy\": train_mean_accuracy,\n",
        "        \"Train Std Dev\": train_std_dev,\n",
        "        \"Test Accuracy\": test_accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1,\n",
        "    })\n",
        "\n",
        "# Convert results to a DataFrame for easy comparison\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Save results to Excel\n",
        "results_df.to_excel(\"optimized_model_results.xlsx\", index=False)\n",
        "\n",
        "# Print final results\n",
        "print(\"Final Model Evaluation Results:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime\n"
      ],
      "metadata": {
        "id": "04ex1DBdsAmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn imbalanced-learn\n"
      ],
      "metadata": {
        "id": "g5Oe2SKLsDSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xv0ONsgEsK9L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}