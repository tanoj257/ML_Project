{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlRQwRhbyoxW",
        "outputId": "69501f45-cbfe-4b37-a237-535e8e053807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = r\"/content/training_with_glove embeddings_split.xlsx\"\n",
        "data = pd.read_excel(file_path, engine='openpyxl')\n",
        "\n",
        "# Define features and target\n",
        "X = data.drop(columns=['input', 'Class'])\n",
        "y = data['Class']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the models and parameter grids\n",
        "models = {\n",
        "    'LogisticRegression': {\n",
        "        'model': LogisticRegression(),\n",
        "        'params': {\n",
        "            'model__C': np.logspace(-4, 4, 10),\n",
        "            'model__penalty': ['l1', 'l2'],\n",
        "            'model__solver': ['liblinear', 'saga']\n",
        "        }\n",
        "    },\n",
        "    'RandomForestClassifier': {\n",
        "        'model': RandomForestClassifier(),\n",
        "        'params': {\n",
        "            'model__n_estimators': [50, 100, 200],\n",
        "            'model__max_depth': [None, 10, 20, 30],\n",
        "            'model__min_samples_split': [2, 5, 10],\n",
        "            'model__min_samples_leaf': [1, 2, 4]\n",
        "        }\n",
        "    },\n",
        "    'SVC': {\n",
        "        'model': SVC(),\n",
        "        'params': {\n",
        "            'model__C': np.logspace(-3, 3, 7),\n",
        "            'model__gamma': ['scale', 'auto'],\n",
        "            'model__kernel': ['linear', 'rbf']\n",
        "        }\n",
        "    },\n",
        "    'KNeighborsClassifier': {\n",
        "        'model': KNeighborsClassifier(),\n",
        "        'params': {\n",
        "            'model__n_neighbors': range(3, 15),\n",
        "            'model__weights': ['uniform', 'distance'],\n",
        "            'model__metric': ['euclidean', 'manhattan']\n",
        "        }\n",
        "    },\n",
        "    'GradientBoostingClassifier': {\n",
        "        'model': GradientBoostingClassifier(),\n",
        "        'params': {\n",
        "            'model__n_estimators': [50, 100, 200],\n",
        "            'model__learning_rate': [0.01, 0.1, 0.2],\n",
        "            'model__max_depth': [3, 5, 7]\n",
        "        }\n",
        "    },\n",
        "    'DecisionTreeClassifier': {\n",
        "        'model': DecisionTreeClassifier(),\n",
        "        'params': {\n",
        "            'model__max_depth': [None, 10, 20, 30],\n",
        "            'model__min_samples_split': [2, 5, 10],\n",
        "            'model__min_samples_leaf': [1, 2, 4]\n",
        "        }\n",
        "    },\n",
        "    'XGBClassifier': {\n",
        "        'model': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "        'params': {\n",
        "            'model__n_estimators': [50, 100, 200],\n",
        "            'model__learning_rate': [0.01, 0.1, 0.2],\n",
        "            'model__max_depth': [3, 5, 7]\n",
        "        }\n",
        "    },\n",
        "    'CatBoostClassifier': {\n",
        "        'model': CatBoostClassifier(verbose=0),\n",
        "        'params': {\n",
        "            'model__iterations': [100, 200, 300],\n",
        "            'model__learning_rate': [0.01, 0.1, 0.2],\n",
        "            'model__depth': [3, 5, 7]\n",
        "        }\n",
        "    },\n",
        "    'AdaBoostClassifier': {\n",
        "        'model': AdaBoostClassifier(),\n",
        "        'params': {\n",
        "            'model__n_estimators': [50, 100, 200],\n",
        "            'model__learning_rate': [0.01, 0.1, 0.2]\n",
        "        }\n",
        "    },\n",
        "    'GaussianNB': {\n",
        "        'model': GaussianNB(),\n",
        "        'params': {}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Perform RandomizedSearchCV with PCA\n",
        "results_with_pca = []\n",
        "best_models = {}\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    # Define the pipeline with PCA\n",
        "    pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('pca', PCA(n_components=5)),  # Adjust the number of components as needed\n",
        "        ('model', model_info['model'])\n",
        "    ])\n",
        "\n",
        "    # Perform hyperparameter search if params are available\n",
        "    if model_info['params']:\n",
        "        search = RandomizedSearchCV(pipe, model_info['params'], n_iter=10, cv=5, scoring='accuracy', random_state=42, n_jobs=-1)\n",
        "        search.fit(X_train, y_train)\n",
        "        best_models[model_name] = search.best_estimator_\n",
        "        train_scores = cross_val_score(search.best_estimator_, X_train, y_train, cv=5, scoring='accuracy')\n",
        "        train_mean = np.mean(train_scores)\n",
        "        train_std = np.std(train_scores)\n",
        "        results_with_pca.append({\n",
        "            'Model': model_name,\n",
        "            'Best Parameters': search.best_params_,\n",
        "            'Best CV Score': search.best_score_,\n",
        "            'Train Mean Accuracy': train_mean,\n",
        "            'Train Std Dev': train_std\n",
        "        })\n",
        "        print(f\"Best parameters for {model_name} with PCA: {search.best_params_}\")\n",
        "        print(f\"Best CV score for {model_name} with PCA: {search.best_score_:.4f}\")\n",
        "    else:\n",
        "        pipe.fit(X_train, y_train)\n",
        "        best_models[model_name] = pipe\n",
        "        train_scores = cross_val_score(pipe, X_train, y_train, cv=5, scoring='accuracy')\n",
        "        train_mean = np.mean(train_scores)\n",
        "        train_std = np.std(train_scores)\n",
        "        results_with_pca.append({\n",
        "            'Model': model_name,\n",
        "            'Best Parameters': \"None\",\n",
        "            'Best CV Score': train_mean,\n",
        "            'Train Mean Accuracy': train_mean,\n",
        "            'Train Std Dev': train_std\n",
        "        })\n",
        "\n",
        "# Evaluate models with PCA on the test set\n",
        "for model_name, model in best_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"Classification report for {model_name} with PCA:\\n{classification_report(y_test, y_pred)}\\n\")\n",
        "\n",
        "# Convert results with PCA to DataFrame\n",
        "results_pca_df = pd.DataFrame(results_with_pca)\n",
        "print(results_pca_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t9bfiVjy4wy",
        "outputId": "ca3ce6c2-5f31-4fc5-8209-ffb8d9dc5a23"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for LogisticRegression with PCA: {'model__solver': 'liblinear', 'model__penalty': 'l1', 'model__C': 0.3593813663804626}\n",
            "Best CV score for LogisticRegression with PCA: 0.4315\n",
            "Best parameters for RandomForestClassifier with PCA: {'model__n_estimators': 200, 'model__min_samples_split': 2, 'model__min_samples_leaf': 1, 'model__max_depth': 30}\n",
            "Best CV score for RandomForestClassifier with PCA: 0.4933\n",
            "Best parameters for SVC with PCA: {'model__kernel': 'rbf', 'model__gamma': 'scale', 'model__C': 10.0}\n",
            "Best CV score for SVC with PCA: 0.4755\n",
            "Best parameters for KNeighborsClassifier with PCA: {'model__weights': 'distance', 'model__n_neighbors': 9, 'model__metric': 'manhattan'}\n",
            "Best CV score for KNeighborsClassifier with PCA: 0.4762\n",
            "Best parameters for GradientBoostingClassifier with PCA: {'model__n_estimators': 50, 'model__max_depth': 5, 'model__learning_rate': 0.1}\n",
            "Best CV score for GradientBoostingClassifier with PCA: 0.4799\n",
            "Best parameters for DecisionTreeClassifier with PCA: {'model__min_samples_split': 10, 'model__min_samples_leaf': 4, 'model__max_depth': 20}\n",
            "Best CV score for DecisionTreeClassifier with PCA: 0.4606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:57:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:57:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:57:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:57:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:57:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:57:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for XGBClassifier with PCA: {'model__n_estimators': 100, 'model__max_depth': 7, 'model__learning_rate': 0.1}\n",
            "Best CV score for XGBClassifier with PCA: 0.4806\n",
            "Best parameters for CatBoostClassifier with PCA: {'model__learning_rate': 0.2, 'model__iterations': 300, 'model__depth': 5}\n",
            "Best CV score for CatBoostClassifier with PCA: 0.4881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for AdaBoostClassifier with PCA: {'model__n_estimators': 200, 'model__learning_rate': 0.1}\n",
            "Best CV score for AdaBoostClassifier with PCA: 0.4524\n",
            "Classification report for LogisticRegression with PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.34      0.45       125\n",
            "           1       0.40      0.78      0.53       124\n",
            "           2       0.23      0.07      0.11        87\n",
            "\n",
            "    accuracy                           0.43       336\n",
            "   macro avg       0.42      0.40      0.36       336\n",
            "weighted avg       0.44      0.43      0.39       336\n",
            "\n",
            "\n",
            "Classification report for RandomForestClassifier with PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.45      0.49       125\n",
            "           1       0.41      0.50      0.45       124\n",
            "           2       0.56      0.51      0.53        87\n",
            "\n",
            "    accuracy                           0.48       336\n",
            "   macro avg       0.50      0.48      0.49       336\n",
            "weighted avg       0.49      0.48      0.48       336\n",
            "\n",
            "\n",
            "Classification report for SVC with PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.34      0.42       125\n",
            "           1       0.41      0.63      0.50       124\n",
            "           2       0.49      0.37      0.42        87\n",
            "\n",
            "    accuracy                           0.46       336\n",
            "   macro avg       0.48      0.45      0.44       336\n",
            "weighted avg       0.47      0.46      0.45       336\n",
            "\n",
            "\n",
            "Classification report for KNeighborsClassifier with PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.46      0.50       125\n",
            "           1       0.40      0.48      0.44       124\n",
            "           2       0.58      0.51      0.54        87\n",
            "\n",
            "    accuracy                           0.48       336\n",
            "   macro avg       0.50      0.48      0.49       336\n",
            "weighted avg       0.49      0.48      0.49       336\n",
            "\n",
            "\n",
            "Classification report for GradientBoostingClassifier with PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.44      0.48       125\n",
            "           1       0.45      0.57      0.50       124\n",
            "           2       0.55      0.47      0.51        87\n",
            "\n",
            "    accuracy                           0.50       336\n",
            "   macro avg       0.51      0.49      0.50       336\n",
            "weighted avg       0.51      0.50      0.50       336\n",
            "\n",
            "\n",
            "Classification report for DecisionTreeClassifier with PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.48      0.48       125\n",
            "           1       0.41      0.45      0.43       124\n",
            "           2       0.45      0.38      0.41        87\n",
            "\n",
            "    accuracy                           0.44       336\n",
            "   macro avg       0.45      0.44      0.44       336\n",
            "weighted avg       0.45      0.44      0.44       336\n",
            "\n",
            "\n",
            "Classification report for XGBClassifier with PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.47      0.52       125\n",
            "           1       0.46      0.60      0.52       124\n",
            "           2       0.62      0.52      0.56        87\n",
            "\n",
            "    accuracy                           0.53       336\n",
            "   macro avg       0.55      0.53      0.53       336\n",
            "weighted avg       0.54      0.53      0.53       336\n",
            "\n",
            "\n",
            "Classification report for CatBoostClassifier with PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.45      0.48       125\n",
            "           1       0.40      0.49      0.44       124\n",
            "           2       0.59      0.51      0.54        87\n",
            "\n",
            "    accuracy                           0.48       336\n",
            "   macro avg       0.50      0.48      0.49       336\n",
            "weighted avg       0.49      0.48      0.48       336\n",
            "\n",
            "\n",
            "Classification report for AdaBoostClassifier with PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.25      0.32       125\n",
            "           1       0.37      0.74      0.50       124\n",
            "           2       0.43      0.10      0.17        87\n",
            "\n",
            "    accuracy                           0.39       336\n",
            "   macro avg       0.42      0.36      0.33       336\n",
            "weighted avg       0.42      0.39      0.35       336\n",
            "\n",
            "\n",
            "Classification report for GaussianNB with PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.30      0.38       125\n",
            "           1       0.35      0.57      0.44       124\n",
            "           2       0.33      0.25      0.29        87\n",
            "\n",
            "    accuracy                           0.39       336\n",
            "   macro avg       0.41      0.37      0.37       336\n",
            "weighted avg       0.42      0.39      0.38       336\n",
            "\n",
            "\n",
            "                        Model  \\\n",
            "0          LogisticRegression   \n",
            "1      RandomForestClassifier   \n",
            "2                         SVC   \n",
            "3        KNeighborsClassifier   \n",
            "4  GradientBoostingClassifier   \n",
            "5      DecisionTreeClassifier   \n",
            "6               XGBClassifier   \n",
            "7          CatBoostClassifier   \n",
            "8          AdaBoostClassifier   \n",
            "9                  GaussianNB   \n",
            "\n",
            "                                     Best Parameters  Best CV Score  \\\n",
            "0  {'model__solver': 'liblinear', 'model__penalty...       0.431537   \n",
            "1  {'model__n_estimators': 200, 'model__min_sampl...       0.493311   \n",
            "2  {'model__kernel': 'rbf', 'model__gamma': 'scal...       0.475479   \n",
            "3  {'model__weights': 'distance', 'model__n_neigh...       0.476222   \n",
            "4  {'model__n_estimators': 50, 'model__max_depth'...       0.479906   \n",
            "5  {'model__min_samples_split': 10, 'model__min_s...       0.460550   \n",
            "6  {'model__n_estimators': 100, 'model__max_depth...       0.480650   \n",
            "7  {'model__learning_rate': 0.2, 'model__iteratio...       0.488101   \n",
            "8  {'model__n_estimators': 200, 'model__learning_...       0.452397   \n",
            "9                                               None       0.437519   \n",
            "\n",
            "   Train Mean Accuracy  Train Std Dev  \n",
            "0             0.431537       0.016856  \n",
            "1             0.488856       0.025923  \n",
            "2             0.475479       0.034016  \n",
            "3             0.473992       0.032213  \n",
            "4             0.477679       0.027064  \n",
            "5             0.454591       0.020359  \n",
            "6             0.478416       0.017510  \n",
            "7             0.482153       0.029589  \n",
            "8             0.452397       0.029295  \n",
            "9             0.437519       0.025284  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X650yiFzzFR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DON'T TOUCH THE COMPUTER"
      ],
      "metadata": {
        "id": "hNaAkACPy5ZO"
      }
    }
  ]
}